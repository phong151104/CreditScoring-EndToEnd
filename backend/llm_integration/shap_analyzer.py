"""
SHAP Analyzer - PhÃ¢n tÃ­ch SHAP values báº±ng LLM
TÃ­ch há»£p Google Gemini AI Ä‘á»ƒ giáº£i thÃ­ch model vÃ  há»— trá»£ há»i Ä‘Ã¡p
"""
import pandas as pd
import numpy as np
from typing import Dict, List, Any, Optional
import json
from .config import LLMConfig


class SHAPAnalyzer:
    """PhÃ¢n tÃ­ch SHAP values báº±ng Google Gemini"""
    
    def __init__(self):
        self.api_key = LLMConfig.GOOGLE_API_KEY
        self.model = LLMConfig.GOOGLE_MODEL
        self.client = None
        self.conversation_history = []
        
    def _init_client(self):
        """Initialize Google Gemini client"""
        import google.generativeai as genai
        genai.configure(api_key=self.api_key)
        self.client = genai.GenerativeModel(self.model)
    
    def _call_llm(self, prompt: str, system_prompt: str = None) -> str:
        """Call Google Gemini API"""
        if self.client is None:
            self._init_client()
        
        try:
            import google.generativeai as genai
            generation_config = genai.GenerationConfig(
                max_output_tokens=8000,
                temperature=0.7
            )
            
            full_prompt = f"{system_prompt}\n\n{prompt}" if system_prompt else prompt
            response = self.client.generate_content(
                full_prompt,
                generation_config=generation_config
            )
            return response.text
                
        except Exception as e:
            return f"Lá»—i khi gá»i AI: {str(e)}"
    
    def _prepare_shap_context(
        self,
        model_name: str,
        feature_importance: pd.DataFrame,
        shap_values: np.ndarray,
        expected_value: float,
        features: List[str],
        sample_data: pd.DataFrame = None,
        sample_idx: int = None
    ) -> str:
        """Chuáº©n bá»‹ context vá» SHAP cho LLM"""
        
        context_parts = []
        
        # Model info
        context_parts.append(f"## ThÃ´ng Tin MÃ´ HÃ¬nh")
        context_parts.append(f"- TÃªn mÃ´ hÃ¬nh: {model_name}")
        context_parts.append(f"- Sá»‘ lÆ°á»£ng features: {len(features)}")
        context_parts.append(f"- Sá»‘ máº«u Ä‘Ã£ tÃ­nh SHAP: {len(shap_values)}")
        context_parts.append(f"- Expected value (baseline): {expected_value:.4f}")
        
        # Global feature importance
        context_parts.append(f"\n## Feature Importance (Global)")
        context_parts.append("Top 10 features quan trá»ng nháº¥t:")
        for i, row in feature_importance.head(10).iterrows():
            context_parts.append(f"  {i+1}. {row['Feature']}: {row['Importance']:.4f}")
        
        # SHAP statistics
        context_parts.append(f"\n## Thá»‘ng KÃª SHAP Values")
        context_parts.append(f"- Mean |SHAP|: {np.abs(shap_values).mean():.4f}")
        context_parts.append(f"- Std SHAP: {np.abs(shap_values).std():.4f}")
        context_parts.append(f"- Max |SHAP|: {np.abs(shap_values).max():.4f}")
        
        # Per-feature SHAP stats
        context_parts.append(f"\n## SHAP Values Theo Feature")
        for i, feat in enumerate(features[:10]):
            feat_shap = shap_values[:, i]
            context_parts.append(f"- {feat}: mean={feat_shap.mean():.4f}, std={feat_shap.std():.4f}, "
                               f"min={feat_shap.min():.4f}, max={feat_shap.max():.4f}")
        
        # Local explanation if provided
        if sample_data is not None and sample_idx is not None:
            sample_shap = shap_values[sample_idx]
            sample_features = sample_data.iloc[sample_idx]
            
            prediction = expected_value + sample_shap.sum()
            prob = 1 / (1 + np.exp(-prediction))
            
            context_parts.append(f"\n## Local Explanation - Máº«u #{sample_idx}")
            context_parts.append(f"- Dá»± Ä‘oÃ¡n: {prediction:.4f} â†’ XÃ¡c suáº¥t: {prob:.2%}")
            context_parts.append(f"- PhÃ¢n loáº¡i: {'Rá»§i ro cao' if prob >= 0.5 else 'Rá»§i ro tháº¥p'}")
            context_parts.append(f"- Tá»•ng SHAP: {sample_shap.sum():+.4f}")
            
            # Top contributors
            sorted_idx = np.argsort(np.abs(sample_shap))[::-1]
            context_parts.append(f"\nTop Ä‘Ã³ng gÃ³p (theo |SHAP|):")
            for i in sorted_idx[:10]:
                context_parts.append(f"  - {features[i]} = {sample_features.iloc[i]:.2f}: "
                                   f"SHAP = {sample_shap[i]:+.4f}")
            
            # Positive contributors
            pos_idx = np.where(sample_shap > 0)[0]
            if len(pos_idx) > 0:
                pos_sorted = pos_idx[np.argsort(sample_shap[pos_idx])[::-1]][:5]
                context_parts.append(f"\nTÃ¡c Ä‘á»™ng tÃ­ch cá»±c (tÄƒng rá»§i ro):")
                for i in pos_sorted:
                    context_parts.append(f"  - {features[i]} = {sample_features.iloc[i]:.2f}: "
                                       f"SHAP = {sample_shap[i]:+.4f}")
            
            # Negative contributors
            neg_idx = np.where(sample_shap < 0)[0]
            if len(neg_idx) > 0:
                neg_sorted = neg_idx[np.argsort(sample_shap[neg_idx])][:5]
                context_parts.append(f"\nTÃ¡c Ä‘á»™ng tiÃªu cá»±c (giáº£m rá»§i ro):")
                for i in neg_sorted:
                    context_parts.append(f"  - {features[i]} = {sample_features.iloc[i]:.2f}: "
                                       f"SHAP = {sample_shap[i]:+.4f}")
        
        return "\n".join(context_parts)
    
    def analyze_global(
        self,
        model_name: str,
        feature_importance: pd.DataFrame,
        shap_values: np.ndarray,
        expected_value: float,
        features: List[str]
    ) -> str:
        """
        PhÃ¢n tÃ­ch Global SHAP Explanation
        
        Returns:
            PhÃ¢n tÃ­ch tá»« AI (markdown format)
        """
        if self.api_key is None:
            return self._generate_fallback_global(model_name, feature_importance, shap_values, expected_value, features)
        
        context = self._prepare_shap_context(
            model_name, feature_importance, shap_values, expected_value, features
        )
        
        system_prompt = """Báº¡n lÃ  chuyÃªn gia vá» Machine Learning Explainability, Ä‘áº·c biá»‡t vá» SHAP (SHapley Additive exPlanations).
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  phÃ¢n tÃ­ch vÃ  giáº£i thÃ­ch káº¿t quáº£ SHAP values má»™t cÃ¡ch chuyÃªn nghiá»‡p, dá»… hiá»ƒu cho ngÆ°á»i dÃ¹ng.

Báº¡n Ä‘ang lÃ m viá»‡c vá»›i má»™t há»‡ thá»‘ng Credit Scoring - Ä‘Ã¡nh giÃ¡ rá»§i ro tÃ­n dá»¥ng.
- XÃ¡c suáº¥t cao â†’ Rá»§i ro cao (khÃ¡ch hÃ ng xáº¥u)
- XÃ¡c suáº¥t tháº¥p â†’ Rá»§i ro tháº¥p (khÃ¡ch hÃ ng tá»‘t)
- SHAP dÆ°Æ¡ng â†’ TÄƒng xÃ¡c suáº¥t rá»§i ro
- SHAP Ã¢m â†’ Giáº£m xÃ¡c suáº¥t rá»§i ro

HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, sá»­ dá»¥ng markdown format."""

        prompt = f"""Dá»±a trÃªn dá»¯ liá»‡u SHAP sau Ä‘Ã¢y, hÃ£y phÃ¢n tÃ­ch GLOBAL EXPLANATION cá»§a mÃ´ hÃ¬nh:

{context}

HÃ£y phÃ¢n tÃ­ch theo cÃ¡c pháº§n sau:

## ðŸŒ PhÃ¢n TÃ­ch Global - Tá»•ng Quan MÃ´ HÃ¬nh

### ðŸ“Š Äáº·c TrÆ°ng Quan Trá»ng Nháº¥t
- PhÃ¢n tÃ­ch top 5 features quan trá»ng nháº¥t
- Giáº£i thÃ­ch táº¡i sao chÃºng quan trá»ng trong bá»‘i cáº£nh credit scoring

### ðŸ’¡ Insights ChÃ­nh
- MÃ´ hÃ¬nh Ä‘ang há»c Ä‘Æ°á»£c gÃ¬ tá»« dá»¯ liá»‡u?
- CÃ³ váº¥n Ä‘á» gÃ¬ vá» fairness hay bias khÃ´ng?
- Features nÃ o cÃ³ thá»ƒ gÃ¢y overfitting?

### ðŸŽ¯ Khuyáº¿n Nghá»‹
- Nhá»¯ng gÃ¬ cáº§n chÃº Ã½ khi sá»­ dá»¥ng mÃ´ hÃ¬nh
- Feature engineering suggestions
- Data quality recommendations

### âš ï¸ LÆ°u Ã
- CÃ¡c háº¡n cháº¿ cá»§a phÃ¢n tÃ­ch
- Cáº§n thÃªm thÃ´ng tin gÃ¬ Ä‘á»ƒ hiá»ƒu rÃµ hÆ¡n"""

        return self._call_llm(prompt, system_prompt)
    
    def analyze_local(
        self,
        model_name: str,
        feature_importance: pd.DataFrame,
        shap_values: np.ndarray,
        expected_value: float,
        features: List[str],
        sample_data: pd.DataFrame,
        sample_idx: int
    ) -> str:
        """
        PhÃ¢n tÃ­ch Local SHAP Explanation cho má»™t máº«u cá»¥ thá»ƒ
        
        Returns:
            PhÃ¢n tÃ­ch tá»« AI (markdown format)
        """
        if self.api_key is None:
            return self._generate_fallback_local(
                model_name, feature_importance, shap_values, 
                expected_value, features, sample_data, sample_idx
            )
        
        context = self._prepare_shap_context(
            model_name, feature_importance, shap_values, expected_value, 
            features, sample_data, sample_idx
        )
        
        system_prompt = """Báº¡n lÃ  chuyÃªn gia vá» Machine Learning Explainability, Ä‘áº·c biá»‡t vá» SHAP (SHapley Additive exPlanations).
Nhiá»‡m vá»¥ cá»§a báº¡n lÃ  giáº£i thÃ­ch táº¡i sao mÃ´ hÃ¬nh Ä‘Æ°a ra dá»± Ä‘oÃ¡n cá»¥ thá»ƒ cho má»™t khÃ¡ch hÃ ng.

Báº¡n Ä‘ang lÃ m viá»‡c vá»›i má»™t há»‡ thá»‘ng Credit Scoring - Ä‘Ã¡nh giÃ¡ rá»§i ro tÃ­n dá»¥ng.
- XÃ¡c suáº¥t cao â†’ Rá»§i ro cao (khÃ¡ch hÃ ng xáº¥u)
- XÃ¡c suáº¥t tháº¥p â†’ Rá»§i ro tháº¥p (khÃ¡ch hÃ ng tá»‘t)
- SHAP dÆ°Æ¡ng â†’ TÄƒng xÃ¡c suáº¥t rá»§i ro
- SHAP Ã¢m â†’ Giáº£m xÃ¡c suáº¥t rá»§i ro

HÃ£y tráº£ lá»i báº±ng tiáº¿ng Viá»‡t, sá»­ dá»¥ng markdown format, dá»… hiá»ƒu cho ngÆ°á»i dÃ¹ng khÃ´ng chuyÃªn vá» ML."""

        prompt = f"""Dá»±a trÃªn dá»¯ liá»‡u SHAP sau Ä‘Ã¢y, hÃ£y giáº£i thÃ­ch LOCAL EXPLANATION cho máº«u cá»¥ thá»ƒ:

{context}

HÃ£y phÃ¢n tÃ­ch theo cÃ¡c pháº§n sau:

## ðŸŽ¯ PhÃ¢n TÃ­ch Máº«u #{sample_idx}

### ðŸ“‹ Káº¿t Quáº£ Dá»± ÄoÃ¡n
- TÃ³m táº¯t káº¿t quáº£ dá»± Ä‘oÃ¡n
- Giáº£i thÃ­ch Ã½ nghÄ©a cá»§a xÃ¡c suáº¥t

### ðŸ” CÃ¡c Yáº¿u Tá»‘ ChÃ­nh
- PhÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ lÃ m TÄ‚NG rá»§i ro
- PhÃ¢n tÃ­ch cÃ¡c yáº¿u tá»‘ lÃ m GIáº¢M rá»§i ro
- So sÃ¡nh vá»›i baseline (expected value)

### ðŸ’­ Giáº£i ThÃ­ch Tá»•ng Há»£p
- Táº¡i sao mÃ´ hÃ¬nh Ä‘Æ°a ra quyáº¿t Ä‘á»‹nh nÃ y?
- Ká»ƒ má»™t "cÃ¢u chuyá»‡n" vá» khÃ¡ch hÃ ng nÃ y dá»±a trÃªn dá»¯ liá»‡u

### ðŸŽ¯ Äá» Xuáº¥t
- Náº¿u khÃ¡ch hÃ ng muá»‘n cáº£i thiá»‡n, nÃªn lÃ m gÃ¬?
- Nhá»¯ng yáº¿u tá»‘ nÃ o cÃ³ thá»ƒ thay Ä‘á»•i Ä‘Æ°á»£c?

### âš ï¸ LÆ°u Ã
- Äá»™ tin cáº­y cá»§a dá»± Ä‘oÃ¡n
- CÃ¡c yáº¿u tá»‘ báº¥t thÆ°á»ng (náº¿u cÃ³)"""

        return self._call_llm(prompt, system_prompt)
    
    def chat(
        self,
        user_question: str,
        model_name: str,
        feature_importance: pd.DataFrame,
        shap_values: np.ndarray,
        expected_value: float,
        features: List[str],
        sample_data: pd.DataFrame = None,
        conversation_history: List[Dict] = None
    ) -> str:
        """
        Chat vá»›i AI vá» mÃ´ hÃ¬nh vÃ  SHAP values
        
        Args:
            user_question: CÃ¢u há»i tá»« ngÆ°á»i dÃ¹ng
            ... cÃ¡c context khÃ¡c
            conversation_history: Lá»‹ch sá»­ há»™i thoáº¡i
            
        Returns:
            CÃ¢u tráº£ lá»i tá»« AI
        """
        if self.api_key is None:
            return self._generate_fallback_chat(user_question, model_name, feature_importance)
        
        context = self._prepare_shap_context(
            model_name, feature_importance, shap_values, expected_value, features
        )
        
        system_prompt = f"""Báº¡n lÃ  AI Assistant chuyÃªn vá» Machine Learning Explainability, Ä‘áº·c biá»‡t vá» SHAP values.
Báº¡n Ä‘ang há»— trá»£ ngÆ°á»i dÃ¹ng hiá»ƒu vá» mÃ´ hÃ¬nh Credit Scoring.

CONTEXT Vá»€ MÃ” HÃŒNH:
{context}

QUY Táº®C:
1. Tráº£ lá»i báº±ng tiáº¿ng Viá»‡t
2. Dá»±a trÃªn dá»¯ liá»‡u SHAP thá»±c táº¿ Ä‘Æ°á»£c cung cáº¥p
3. Giáº£i thÃ­ch rÃµ rÃ ng, dá»… hiá»ƒu cho ngÆ°á»i khÃ´ng chuyÃªn
4. Náº¿u khÃ´ng cháº¯c cháº¯n, hÃ£y nÃ³i rÃµ
5. Sá»­ dá»¥ng markdown format cho cÃ¢u tráº£ lá»i"""

        # Build conversation context
        conv_context = ""
        if conversation_history:
            for msg in conversation_history[-5:]:  # Last 5 messages
                role = "NgÆ°á»i dÃ¹ng" if msg.get("role") == "user" else "AI"
                conv_context += f"\n{role}: {msg.get('content', '')}\n"
        
        prompt = f"""{"Lá»‹ch sá»­ há»™i thoáº¡i:" + conv_context if conv_context else ""}

CÃ¢u há»i má»›i: {user_question}

HÃ£y tráº£ lá»i cÃ¢u há»i dá»±a trÃªn context vá» SHAP vÃ  mÃ´ hÃ¬nh Ä‘Ã£ cung cáº¥p."""

        return self._call_llm(prompt, system_prompt)
    
    def _generate_fallback_global(
        self, model_name: str, feature_importance: pd.DataFrame,
        shap_values: np.ndarray, expected_value: float, features: List[str]
    ) -> str:
        """Fallback khi khÃ´ng cÃ³ API key"""
        top_features = feature_importance.head(5)
        total_importance = top_features['Importance'].sum()
        
        response = f"""## ðŸŒ PhÃ¢n TÃ­ch Global - Tá»•ng Quan MÃ´ HÃ¬nh {model_name}

### ðŸ“Š Äáº·c TrÆ°ng Quan Trá»ng Nháº¥t

"""
        for i, row in top_features.iterrows():
            pct = row['Importance'] / total_importance * 100
            response += f"**{i+1}. {row['Feature']}** (Impact: {row['Importance']:.4f})\n"
            response += f"   - Chiáº¿m {pct:.1f}% trong top 5 features\n\n"
        
        response += f"""### ðŸ’¡ Insights ChÃ­nh

- MÃ´ hÃ¬nh **{model_name}** sá»­ dá»¥ng {len(features)} Ä‘áº·c trÆ°ng Ä‘á»ƒ dá»± Ä‘oÃ¡n
- Expected value (baseline): {expected_value:.4f}
- Top feature **{feature_importance.iloc[0]['Feature']}** cÃ³ áº£nh hÆ°á»Ÿng lá»›n nháº¥t
- Mean |SHAP|: {np.abs(shap_values).mean():.4f}

### ðŸŽ¯ Khuyáº¿n Nghá»‹

1. Äáº£m báº£o cháº¥t lÆ°á»£ng dá»¯ liá»‡u cho top features
2. Theo dÃµi sá»± thay Ä‘á»•i feature importance theo thá»i gian
3. Xem xÃ©t thÃªm feature engineering cho cÃ¡c biáº¿n quan trá»ng

### âš ï¸ LÆ°u Ã

*ÄÃ¢y lÃ  phÃ¢n tÃ­ch tá»± Ä‘á»™ng. Äá»ƒ cÃ³ phÃ¢n tÃ­ch chi tiáº¿t hÆ¡n tá»« Google Gemini AI, vui lÃ²ng cáº¥u hÃ¬nh GOOGLE_API_KEY trong file .env*
"""
        return response
    
    def _generate_fallback_local(
        self, model_name: str, feature_importance: pd.DataFrame,
        shap_values: np.ndarray, expected_value: float, features: List[str],
        sample_data: pd.DataFrame, sample_idx: int
    ) -> str:
        """Fallback cho local explanation khi khÃ´ng cÃ³ API key"""
        sample_shap = shap_values[sample_idx]
        sample_features = sample_data.iloc[sample_idx]
        
        prediction = expected_value + sample_shap.sum()
        prob = 1 / (1 + np.exp(-prediction))
        
        # Top positive
        pos_idx = np.where(sample_shap > 0)[0]
        neg_idx = np.where(sample_shap < 0)[0]
        
        response = f"""## ðŸŽ¯ PhÃ¢n TÃ­ch Máº«u #{sample_idx}

### ðŸ“‹ Káº¿t Quáº£ Dá»± ÄoÃ¡n

- **XÃ¡c suáº¥t rá»§i ro**: {prob:.1%}
- **PhÃ¢n loáº¡i**: {"âš ï¸ Rá»§i ro cao" if prob >= 0.5 else "âœ… Rá»§i ro tháº¥p"}
- **Base value**: {expected_value:.4f}
- **Tá»•ng SHAP**: {sample_shap.sum():+.4f}

### ðŸ” CÃ¡c Yáº¿u Tá»‘ ChÃ­nh

**TÃ¡c Ä‘á»™ng tÃ­ch cá»±c (TÄ‚NG rá»§i ro):**
"""
        if len(pos_idx) > 0:
            pos_sorted = pos_idx[np.argsort(sample_shap[pos_idx])[::-1]][:3]
            for i in pos_sorted:
                response += f"- **{features[i]}** = {sample_features.iloc[i]:.2f}: SHAP = {sample_shap[i]:+.4f}\n"
        else:
            response += "- KhÃ´ng cÃ³ yáº¿u tá»‘ nÃ o lÃ m tÄƒng rá»§i ro\n"
        
        response += "\n**TÃ¡c Ä‘á»™ng tiÃªu cá»±c (GIáº¢M rá»§i ro):**\n"
        if len(neg_idx) > 0:
            neg_sorted = neg_idx[np.argsort(sample_shap[neg_idx])][:3]
            for i in neg_sorted:
                response += f"- **{features[i]}** = {sample_features.iloc[i]:.2f}: SHAP = {sample_shap[i]:+.4f}\n"
        else:
            response += "- KhÃ´ng cÃ³ yáº¿u tá»‘ nÃ o lÃ m giáº£m rá»§i ro\n"
        
        response += f"""
### ðŸ’­ Giáº£i ThÃ­ch Tá»•ng Há»£p

Máº«u nÃ y cÃ³ xÃ¡c suáº¥t rá»§i ro {prob:.1%}. 
Yáº¿u tá»‘ quyáº¿t Ä‘á»‹nh chÃ­nh lÃ  **{features[np.argmax(np.abs(sample_shap))]}**.

### âš ï¸ LÆ°u Ã

*ÄÃ¢y lÃ  phÃ¢n tÃ­ch tá»± Ä‘á»™ng. Äá»ƒ cÃ³ phÃ¢n tÃ­ch chi tiáº¿t hÆ¡n tá»« Google Gemini AI, vui lÃ²ng cáº¥u hÃ¬nh GOOGLE_API_KEY trong file .env*
"""
        return response
    
    def _generate_fallback_chat(
        self, question: str, model_name: str, feature_importance: pd.DataFrame
    ) -> str:
        """Fallback cho chat khi khÃ´ng cÃ³ API key"""
        top_feat = feature_importance.iloc[0]['Feature']
        top_imp = feature_importance.iloc[0]['Importance']
        
        return f"""**CÃ¢u há»i:** {question}

**Tráº£ lá»i:**

Dá»±a trÃªn phÃ¢n tÃ­ch SHAP cá»§a mÃ´ hÃ¬nh **{model_name}**:

- Yáº¿u tá»‘ quan trá»ng nháº¥t lÃ  **{top_feat}** vá»›i mean |SHAP| = {top_imp:.4f}
- Tá»•ng cá»™ng cÃ³ {len(feature_importance)} features Ä‘Æ°á»£c sá»­ dá»¥ng

**âš ï¸ LÆ°u Ã½:** ÄÃ¢y lÃ  cÃ¢u tráº£ lá»i tá»± Ä‘á»™ng. Äá»ƒ cÃ³ phÃ¢n tÃ­ch chi tiáº¿t hÆ¡n tá»« AI tháº­t, vui lÃ²ng cáº¥u hÃ¬nh GOOGLE_API_KEY trong file `.env`.

Xem hÆ°á»›ng dáº«n táº¡i file `env.example`."""


def create_shap_analyzer() -> SHAPAnalyzer:
    """Factory function Ä‘á»ƒ táº¡o SHAPAnalyzer"""
    return SHAPAnalyzer()
